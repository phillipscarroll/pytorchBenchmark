{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V7mWFNse-pzE"
      },
      "source": [
        "# Train And Test Benchmark Times"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-krbjILr-pzF"
      },
      "source": [
        "## Run Once To Build Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HKnxpr38-pzG"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import random\n",
        "\n",
        "# Constants\n",
        "TRAIN_GOOD_FILE_COUNT = 250\n",
        "TEST_GOOD_FILE_COUNT = 50\n",
        "TRAIN_BAD_FILE_COUNT = 250\n",
        "TEST_BAD_FILE_COUNT = 50\n",
        "DATA_FOLDER = \"data\"\n",
        "WDSDataset_FOLDER = os.path.join(DATA_FOLDER, \"benchmark_dataset\")\n",
        "\n",
        "# Generate Good files\n",
        "good_files = []\n",
        "for i in range(TRAIN_GOOD_FILE_COUNT + TEST_GOOD_FILE_COUNT):\n",
        "    data = {\n",
        "        \"id\": random.randint(100000, 999999),\n",
        "        \"name\": {\n",
        "            \"first\": f\"John\",\n",
        "            \"last\": f\"Doe {i+1}\"\n",
        "        },\n",
        "        \"age\": random.randint(18, 60),\n",
        "        \"score\": {\n",
        "            \"math\": round(random.uniform(0.6, 1.0), 2),\n",
        "            \"science\": round(random.uniform(0.6, 1.0), 2),\n",
        "            \"english\": round(random.uniform(0.6, 1.0), 2)\n",
        "        },\n",
        "        \"address\": {\n",
        "            \"street\": f\"{random.randint(100, 999)} Main St\",\n",
        "            \"city\": \"Anytown\",\n",
        "            \"state\": \"CA\",\n",
        "            \"zip\": f\"{random.randint(10000, 99999)}\"\n",
        "        },\n",
        "        \"contacts\": [\n",
        "            {\"type\": \"email\", \"value\": f\"john.doe{i+1}@example.com\"},\n",
        "            {\"type\": \"phone\", \"value\": f\"555-{random.randint(1000, 9999)}\"}\n",
        "        ]\n",
        "    }\n",
        "    good_files.append(json.dumps(data))\n",
        "\n",
        "# Generate Bad files\n",
        "bad_files = []\n",
        "for i in range(TRAIN_BAD_FILE_COUNT + TEST_BAD_FILE_COUNT):\n",
        "    data = {\n",
        "        \"id\": random.randint(100000, 999999),\n",
        "        \"name\": {\n",
        "            \"first\": f\"John\",\n",
        "            \"last\": f\"Doe {i+1}\"\n",
        "        },\n",
        "        \"age\": random.randint(18, 60),\n",
        "        \"score\": {\n",
        "            \"math\": round(random.uniform(0.4, 0.9), 2),\n",
        "            \"science\": round(random.uniform(0.4, 0.9), 2),\n",
        "            \"english\": round(random.uniform(0.4, 0.9), 2)\n",
        "        },\n",
        "        \"address\": {\n",
        "            \"street\": f\"{random.randint(100, 999)} Main St\",\n",
        "            \"city\": \"Anytown\",\n",
        "            \"state\": \"CA\",\n",
        "            \"zip\": f\"{random.randint(10000, 99999)}\"\n",
        "        },\n",
        "        \"contacts\": [\n",
        "            {\"type\": \"email\", \"value\": f\"john.doe{i+1}@example.com\"},\n",
        "            {\"type\": \"phone\", \"value\": f\"555-{random.randint(1000, 9999)}\"}\n",
        "        ],\n",
        "        \"feedback\": [\"bad\", \"not good\", \"block\"][random.randint(0, 2)]\n",
        "    }\n",
        "    bad_files.append(json.dumps(data))\n",
        "\n",
        "# Create train and test folder structure\n",
        "train_good_folder_path = os.path.join(WDSDataset_FOLDER, \"train\", \"good\")\n",
        "train_bad_folder_path = os.path.join(WDSDataset_FOLDER, \"train\", \"bad\")\n",
        "test_good_folder_path = os.path.join(WDSDataset_FOLDER, \"test\", \"good\")\n",
        "test_bad_folder_path = os.path.join(WDSDataset_FOLDER, \"test\", \"bad\")\n",
        "\n",
        "os.makedirs(train_good_folder_path, exist_ok=True)\n",
        "os.makedirs(train_bad_folder_path, exist_ok=True)\n",
        "os.makedirs(test_good_folder_path, exist_ok=True)\n",
        "os.makedirs(test_bad_folder_path, exist_ok=True)\n",
        "\n",
        "# Save Good files to train/GOOD and test/GOOD folders\n",
        "for i in range(TRAIN_GOOD_FILE_COUNT):\n",
        "    good_file_path = os.path.join(train_good_folder_path, f\"good{i+1}.json\")\n",
        "    with open(good_file_path, \"w\") as f:\n",
        "        f.write(good_files[i])\n",
        "\n",
        "for i in range(TEST_GOOD_FILE_COUNT):\n",
        "    good_file_path = os.path.join(train_good_folder_path, f\"good{i+1}.json\")\n",
        "    with open(good_file_path, \"w\") as f:\n",
        "        f.write(good_files[TRAIN_GOOD_FILE_COUNT + i])\n",
        "\n",
        "# Save Bad files to train/BAD and test/BAD folders\n",
        "for i in range(TRAIN_BAD_FILE_COUNT):\n",
        "    bad_file_path = os.path.join(train_bad_folder_path, f\"bad{i+1}.json\")\n",
        "    with open(bad_file_path, \"w\") as f:\n",
        "        f.write(bad_files[i])\n",
        "\n",
        "for i in range(TEST_BAD_FILE_COUNT):\n",
        "    bad_file_path = os.path.join(train_bad_folder_path, f\"bad{i+1}.json\")\n",
        "    with open(bad_file_path, \"w\") as f:\n",
        "        f.write(bad_files[TRAIN_BAD_FILE_COUNT + i])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GcLiQBnz-pzH"
      },
      "source": [
        "## Benchmark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9tdbV-IA-pzH"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\user\\miniconda3\\envs\\ipex\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "C:\\Users\\user\\miniconda3\\envs\\ipex\\Lib\\site-packages\\torchvision\\io\\image.py:14: UserWarning: Failed to load image Python extension: 'Could not find module 'C:\\Users\\user\\miniconda3\\envs\\ipex\\Lib\\site-packages\\torchvision\\image.pyd' (or one of its dependencies). Try using the full path with constructor syntax.'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
            "  warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: xpu:0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "  0%|                                                                                           | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mFailed to interrupt the Kernel. \n",
            "\u001b[1;31mrequest to http://10.0.0.31:8888/api/kernels/b91f46cf-db99-4f03-ad42-e7e57480f5e6/restart?1738685502594 failed, reason: connect ECONNREFUSED 10.0.0.31:8888. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "from torch.optim import AdamW\n",
        "from torch.amp import GradScaler\n",
        "import time\n",
        "import tqdm\n",
        "\n",
        "# Function to set the number of CPU threads\n",
        "def set_cpu_thread_cap(num_threads):\n",
        "    torch.set_num_threads(num_threads)\n",
        "    torch.set_num_interop_threads(num_threads)\n",
        "    print(f\"Set max CPU threads to: {num_threads}\")\n",
        "\n",
        "# Set the device type and device ID\n",
        "device_type = \"xpu\" if torch.xpu.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device_id = 0  # Change this to the desired device index, e.g., 0 or 1\n",
        "# Combine device type and device ID to create the device variable\n",
        "device = torch.device(f\"{device_type}:{device_id}\" if device_type else \"cpu\")\n",
        "print(f\"Device: {device}\")\n",
        "# If running on CPU, set this manually, otherwise comment out\n",
        "#device = \"cpu\"\n",
        "\n",
        "# If running on CPU, set the number of threads\n",
        "if device == 'cpu':\n",
        "    set_cpu_thread_cap(20)  # Set this to the desired number of CPU threads\n",
        "\n",
        "\n",
        "class JSONDataset(Dataset):\n",
        "    def __init__(self, data_dir, tokenizer, max_length=512):\n",
        "        self.data_dir = data_dir\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "        self.data = []\n",
        "\n",
        "        # Load and preprocess data\n",
        "        for label in ['good', 'bad']:\n",
        "            label_dir = os.path.join(data_dir, label)\n",
        "            for file_name in os.listdir(label_dir):\n",
        "                if file_name.endswith('.json'):\n",
        "                    file_path = os.path.join(label_dir, file_name)\n",
        "                    with open(file_path, 'r') as f:\n",
        "                        script_data = json.load(f)\n",
        "                        # Convert JSON data to a string (simple approach, can be improved)\n",
        "                        text = str(script_data)\n",
        "\n",
        "                        self.data.append((text, label))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text, label = self.data[idx]\n",
        "\n",
        "        # Tokenize the text\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_length,\n",
        "            return_token_type_ids=False,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt',\n",
        "        )\n",
        "\n",
        "        # Convert to tensors\n",
        "        item = {\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'labels': torch.tensor(1 if label == 'good' else 0, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "        return item\n",
        "\n",
        "# Load tokenizer and model\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
        "\n",
        "# Move the model to the device\n",
        "model.to(device)\n",
        "\n",
        "# Dataset and DataLoader\n",
        "train_dir = os.path.join(\"data\", \"benchmark_dataset\", \"train\")\n",
        "test_dir = os.path.join(\"data\", \"benchmark_dataset\", \"test\")\n",
        "\n",
        "train_dataset = JSONDataset(train_dir, tokenizer)\n",
        "test_dataset = JSONDataset(test_dir, tokenizer)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=5, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=5, shuffle=False)\n",
        "\n",
        "# Optimizer\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "\n",
        "# Initialize GradScaler for mixed precision training\n",
        "scaler = torch.GradScaler('xpu')\n",
        "\n",
        "# Training function\n",
        "def train_epoch(model, train_loader, optimizer, scaler):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for step, batch in enumerate(train_loader):\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        with torch.amp.autocast('xpu'):\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            loss = outputs.loss\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(train_loader)\n",
        "\n",
        "# Testing function\n",
        "def test_model(model, test_loader):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            with torch.amp.autocast('xpu'):\n",
        "                outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "                logits = outputs.logits\n",
        "                preds = torch.argmax(logits, dim=-1)\n",
        "\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    accuracy = accuracy_score(all_labels, all_preds)\n",
        "    report = classification_report(all_labels, all_preds, target_names=['bad', 'good'], labels=[0, 1])\n",
        "\n",
        "    return accuracy, report\n",
        "\n",
        "# Training loop\n",
        "epochs = 1\n",
        "\n",
        "benchmarkLoops = 10\n",
        "\n",
        "# Start timer\n",
        "start_time = time.time()\n",
        "\n",
        "# Run the training loop with tqdm for progress bar\n",
        "for i in tqdm.tqdm(range(benchmarkLoops)):\n",
        "    for epoch in range(epochs):\n",
        "        train_loss = train_epoch(model, train_loader, optimizer, scaler)\n",
        "        accuracy, report = test_model(model, test_loader)\n",
        "        # print time and loop number\n",
        "        print(f\"Loop {i+1} - Epoch {epoch+1} - Train Loss: {train_loss:.4f} - Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# End timer\n",
        "end_time = time.time()\n",
        "elapsed_time = end_time - start_time\n",
        "print(f\"Elapsed time: {elapsed_time:.2f} seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6eMjjvT-pzH"
      },
      "source": [
        "# Results\n",
        "\n",
        "Batch Size 5, 1 Epoch, 10 Iterations Mixed Precision\n",
        "\n",
        "* RTX 2080\n",
        "  * Elapsed time: 125.75 seconds\n",
        "* ARC A770 16GB (No AMP)\n",
        "  * Elapsed time: 229.07 seconds\n",
        "* ARC A770 16GB (AMP Working WSL2)\n",
        "  * Elapsed time: 176.26 seconds\n",
        "* ARC B580 12GB (No AMP)\n",
        "  * Elapsed time: 181.56 seconds\n",
        "* ARC B580 12GB (AMP Native Windows)\n",
        "  * Elapsed time: 116.54 seconds\n",
        "  * Stock settings seem just fine for this little card\n",
        "* ARC B580 12GB (AMP Native Windows) +10% voltage - 120% power limit - +250mhz - Mem +20Gbps - 105w @ 3150mhz\n",
        "  * lapsed time: 108.92 seconds\n",
        "* RTX 4070 Super 12GB\n",
        "  * Elapsed time: 83.88 seconds\n",
        "* Titan Xp 12GB\n",
        "  * Elapsed time: 375.25 seconds\n",
        "* i9-14900K 5.4ghz all core locked 64GB 6800MHZ DDR5 20 threads\n",
        "  * Elapsed time: 2381.41 seconds\n",
        "* Ultra 155H ARC 16GB Total with 8GB Shared RAM (Laptop) (No AMP)\n",
        "  * Elapsed time: 1457.17 seconds\n",
        "* RTX 3080 Founders Edition 10GB\n",
        "  * Elapsed time: 75.68\n",
        "* Google Colab Tesla T4 16GB\n",
        "  * Elapsed time: 177.52 seconds\n",
        "* Google Colab A100\n",
        "  * Elapsed time: 55.05 seconds\n",
        "* Google Colab L4\n",
        "  * Elapsed time: 109.60 seconds\n",
        "* RTX 3090 Ti Founders Edition 24GB Factory Settings - 280w power usage\n",
        "  * Elapsed time: 69.82 seconds\n",
        "* RTX 3090 Ti Founders Edition 24GB 1725mhz@0.825v +400 mem - 210w power usage\n",
        "  * Elapsed time: 73.97 seconds\n",
        "* RTX 3090 Ti Founders Edition 24GB 1725mhz@0.825v +1400 mem - 210w power usage\n",
        "  * Elapsed time: 72.56 seconds\n",
        "* RTX 3090 Ti Founders Edition 24GB 2100mhz@0.985v +1400 mem - 255w power usage\n",
        "  * Elapsed time: 67.59 seconds\n",
        "* RTX 3090 Ti Founders Edition 24GB 2070mhz@0.960v +1000 mem - 235w power usage\n",
        "  * Elapsed time: 68.51 seconds\n",
        "* RTX 3090 Ti Founders Edition 24GB 1560mhz@0.800v +800 mem - 130w power usage\n",
        "  * Elapsed time: 97.39 seconds\n",
        "* RTX 3090 Ti Founders Edition 24GB 1770mhz@0.825v +1000 mem - 210w power usage\n",
        "  * Elapsed time: 71.67 seconds\n",
        "  * Somewhere around 1750-1800mhz @ 0.825v +500 to 1000 memory seems to be the sweet spot\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
