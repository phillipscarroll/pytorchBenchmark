{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train And Test Benchmark Times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Once To Build Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "\n",
    "# Constants\n",
    "TRAIN_GOOD_FILE_COUNT = 250\n",
    "TEST_GOOD_FILE_COUNT = 50\n",
    "TRAIN_BAD_FILE_COUNT = 250\n",
    "TEST_BAD_FILE_COUNT = 50\n",
    "DATA_FOLDER = \"data\"\n",
    "WDSDataset_FOLDER = f\"{DATA_FOLDER}/benchmark_dataset\"\n",
    "\n",
    "# Generate Good files\n",
    "good_files = []\n",
    "for i in range(TRAIN_GOOD_FILE_COUNT + TEST_GOOD_FILE_COUNT):\n",
    "    data = {\n",
    "        \"id\": random.randint(100000, 999999),\n",
    "        \"name\": {\n",
    "            \"first\": f\"John\",\n",
    "            \"last\": f\"Doe {i+1}\"\n",
    "        },\n",
    "        \"age\": random.randint(18, 60),\n",
    "        \"score\": {\n",
    "            \"math\": round(random.uniform(0.6, 1.0), 2),\n",
    "            \"science\": round(random.uniform(0.6, 1.0), 2),\n",
    "            \"english\": round(random.uniform(0.6, 1.0), 2)\n",
    "        },\n",
    "        \"address\": {\n",
    "            \"street\": f\"{random.randint(100, 999)} Main St\",\n",
    "            \"city\": \"Anytown\",\n",
    "            \"state\": \"CA\",\n",
    "            \"zip\": f\"{random.randint(10000, 99999)}\"\n",
    "        },\n",
    "        \"contacts\": [\n",
    "            {\"type\": \"email\", \"value\": f\"john.doe{i+1}@example.com\"},\n",
    "            {\"type\": \"phone\", \"value\": f\"555-{random.randint(1000, 9999)}\"}\n",
    "        ]\n",
    "    }\n",
    "    good_files.append(json.dumps(data))\n",
    "\n",
    "# Generate Bad files\n",
    "bad_files = []\n",
    "for i in range(TRAIN_BAD_FILE_COUNT + TEST_BAD_FILE_COUNT):\n",
    "    data = {\n",
    "        \"id\": random.randint(100000, 999999),\n",
    "        \"name\": {\n",
    "            \"first\": f\"John\",\n",
    "            \"last\": f\"Doe {i+1}\"\n",
    "        },\n",
    "        \"age\": random.randint(18, 60),\n",
    "        \"score\": {\n",
    "            \"math\": round(random.uniform(0.4, 0.9), 2),\n",
    "            \"science\": round(random.uniform(0.4, 0.9), 2),\n",
    "            \"english\": round(random.uniform(0.4, 0.9), 2)\n",
    "        },\n",
    "        \"address\": {\n",
    "            \"street\": f\"{random.randint(100, 999)} Main St\",\n",
    "            \"city\": \"Anytown\",\n",
    "            \"state\": \"CA\",\n",
    "            \"zip\": f\"{random.randint(10000, 99999)}\"\n",
    "        },\n",
    "        \"contacts\": [\n",
    "            {\"type\": \"email\", \"value\": f\"john.doe{i+1}@example.com\"},\n",
    "            {\"type\": \"phone\", \"value\": f\"555-{random.randint(1000, 9999)}\"}\n",
    "        ],\n",
    "        \"feedback\": [\"bad\", \"not good\", \"block\"][random.randint(0, 2)]\n",
    "    }\n",
    "    bad_files.append(json.dumps(data))\n",
    "\n",
    "# Create train and test folder structure\n",
    "train_good_folder_path = f\"{WDSDataset_FOLDER}/train/good\"\n",
    "train_bad_folder_path = f\"{WDSDataset_FOLDER}/train/bad\"\n",
    "test_good_folder_path = f\"{WDSDataset_FOLDER}/test/good\"\n",
    "test_bad_folder_path = f\"{WDSDataset_FOLDER}/test/bad\"\n",
    "\n",
    "os.makedirs(train_good_folder_path, exist_ok=True)\n",
    "os.makedirs(train_bad_folder_path, exist_ok=True)\n",
    "os.makedirs(test_good_folder_path, exist_ok=True)\n",
    "os.makedirs(test_bad_folder_path, exist_ok=True)\n",
    "\n",
    "# Save Good files to train/GOOD and test/GOOD folders\n",
    "for i in range(TRAIN_GOOD_FILE_COUNT):\n",
    "    good_file_path = f\"{train_good_folder_path}/good{i+1}.json\"\n",
    "    with open(good_file_path, \"w\") as f:\n",
    "        f.write(good_files[i])\n",
    "\n",
    "for i in range(TEST_GOOD_FILE_COUNT):\n",
    "    good_file_path = f\"{test_good_folder_path}/good{i+1}.json\"\n",
    "    with open(good_file_path, \"w\") as f:\n",
    "        f.write(good_files[TRAIN_GOOD_FILE_COUNT + i])\n",
    "\n",
    "# Save Bad files to train/BAD and test/BAD folders\n",
    "for i in range(TRAIN_BAD_FILE_COUNT):\n",
    "    bad_file_path = f\"{train_bad_folder_path}/bad{i+1}.json\"\n",
    "    with open(bad_file_path, \"w\") as f:\n",
    "        f.write(bad_files[i])\n",
    "\n",
    "for i in range(TEST_BAD_FILE_COUNT):\n",
    "    bad_file_path = f\"{test_bad_folder_path}/bad{i+1}.json\"\n",
    "    with open(bad_file_path, \"w\") as f:\n",
    "        f.write(bad_files[TRAIN_BAD_FILE_COUNT + i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\miniconda3\\envs\\cuda\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  0%|                                                                                           | 0/10 [00:00<?, ?it/s]C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_6456\\3284496815.py:117: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_6456\\3284496815.py:141: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      " 10%|████████▎                                                                          | 1/10 [00:31<04:41, 31.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 1 - Epoch 1 - Train Loss: 0.0832 - Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_6456\\3284496815.py:117: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_6456\\3284496815.py:141: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      " 20%|████████████████▌                                                                  | 2/10 [01:01<04:07, 30.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 2 - Epoch 1 - Train Loss: 0.0015 - Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_6456\\3284496815.py:117: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      " 20%|████████████████▌                                                                  | 2/10 [01:13<04:54, 36.81s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 165\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm\u001b[38;5;241m.\u001b[39mtqdm(\u001b[38;5;28mrange\u001b[39m(benchmarkLoops)):\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m--> 165\u001b[0m         train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscaler\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    166\u001b[0m         accuracy, report \u001b[38;5;241m=\u001b[39m test_model(model, test_loader)\n\u001b[0;32m    167\u001b[0m         \u001b[38;5;66;03m# print time and loop number\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[1], line 122\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[1;34m(model, train_loader, optimizer, scaler)\u001b[0m\n\u001b[0;32m    119\u001b[0m     loss \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mloss\n\u001b[0;32m    121\u001b[0m scaler\u001b[38;5;241m.\u001b[39mscale(loss)\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m--> 122\u001b[0m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    123\u001b[0m scaler\u001b[38;5;241m.\u001b[39mupdate()\n\u001b[0;32m    125\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\cuda\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:457\u001b[0m, in \u001b[0;36mGradScaler.step\u001b[1;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[0;32m    451\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munscale_(optimizer)\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[0;32m    454\u001b[0m     \u001b[38;5;28mlen\u001b[39m(optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    455\u001b[0m ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo inf checks were recorded for this optimizer.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 457\u001b[0m retval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_opt_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    459\u001b[0m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstage\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m OptState\u001b[38;5;241m.\u001b[39mSTEPPED\n\u001b[0;32m    461\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\cuda\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:351\u001b[0m, in \u001b[0;36mGradScaler._maybe_opt_step\u001b[1;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_maybe_opt_step\u001b[39m(\n\u001b[0;32m    344\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    345\u001b[0m     optimizer: torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mOptimizer,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    348\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    349\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[0;32m    350\u001b[0m     retval: Optional[\u001b[38;5;28mfloat\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 351\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moptimizer_state\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf_per_device\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    352\u001b[0m         retval \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mstep(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    353\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\cuda\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:351\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_maybe_opt_step\u001b[39m(\n\u001b[0;32m    344\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    345\u001b[0m     optimizer: torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mOptimizer,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    348\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    349\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[0;32m    350\u001b[0m     retval: Optional[\u001b[38;5;28mfloat\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 351\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28msum\u001b[39m(\u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[0;32m    352\u001b[0m         retval \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mstep(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    353\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torch.optim import AdamW\n",
    "from torch.amp import GradScaler\n",
    "import time\n",
    "import tqdm\n",
    "\n",
    "# Function to set the number of CPU threads\n",
    "def set_cpu_thread_cap(num_threads):\n",
    "    torch.set_num_threads(num_threads)\n",
    "    torch.set_num_interop_threads(num_threads)\n",
    "    print(f\"Set max CPU threads to: {num_threads}\")\n",
    "\n",
    "# Set the device type and device ID\n",
    "device_type = \"xpu\" if torch.xpu.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device_id = 0  # Change this to the desired device index, e.g., 0 or 1\n",
    "# Combine device type and device ID to create the device variable\n",
    "device = torch.device(f\"{device_type}:{device_id}\" if device_type else \"cpu\")\n",
    "print(f\"Device: {device}\")\n",
    "# If running on CPU, set this manually, otherwise comment out\n",
    "#device = \"cpu\"\n",
    "\n",
    "# If running on CPU, set the number of threads\n",
    "if device == 'cpu':\n",
    "    set_cpu_thread_cap(20)  # Set this to the desired number of CPU threads\n",
    "\n",
    "\n",
    "class JSONDataset(Dataset):\n",
    "    def __init__(self, data_dir, tokenizer, max_length=512):\n",
    "        self.data_dir = data_dir\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.data = []\n",
    "        \n",
    "        # Load and preprocess data\n",
    "        for label in ['good', 'bad']:\n",
    "            label_dir = os.path.join(data_dir, label)\n",
    "            for file_name in os.listdir(label_dir):\n",
    "                if file_name.endswith('.json'):\n",
    "                    file_path = os.path.join(label_dir, file_name)\n",
    "                    with open(file_path, 'r') as f:\n",
    "                        script_data = json.load(f)\n",
    "                        # Convert JSON data to a string (simple approach, can be improved)\n",
    "                        text = str(script_data)\n",
    "                        \n",
    "                        self.data.append((text, label))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text, label = self.data[idx]\n",
    "        \n",
    "        # Tokenize the text\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "        \n",
    "        # Convert to tensors\n",
    "        item = {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(1 if label == 'good' else 0, dtype=torch.long)\n",
    "        }\n",
    "        \n",
    "        return item\n",
    "\n",
    "# Load tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "\n",
    "# Move the model to the device\n",
    "model.to(device)\n",
    "\n",
    "# Dataset and DataLoader\n",
    "train_dir = 'data\\\\benchmark_dataset\\\\train'\n",
    "test_dir = 'data\\\\benchmark_dataset\\\\test'\n",
    "\n",
    "train_dataset = JSONDataset(train_dir, tokenizer)\n",
    "test_dataset = JSONDataset(test_dir, tokenizer)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=2, shuffle=False)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "# Initialize GradScaler for mixed precision training\n",
    "scaler = GradScaler()\n",
    "\n",
    "# Training function\n",
    "def train_epoch(model, train_loader, optimizer, scaler):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for step, batch in enumerate(train_loader):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        with autocast():\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "        \n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "# Testing function\n",
    "def test_model(model, test_loader):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            with autocast():\n",
    "                outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "                logits = outputs.logits\n",
    "                preds = torch.argmax(logits, dim=-1)\n",
    "            \n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    report = classification_report(all_labels, all_preds, target_names=['bad', 'good'])\n",
    "    \n",
    "    return accuracy, report\n",
    "\n",
    "# Training loop\n",
    "epochs = 1\n",
    "\n",
    "benchmarkLoops = 10\n",
    "\n",
    "# Start timer\n",
    "start_time = time.time()\n",
    "\n",
    "# Run the training loop with tqdm for progress bar\n",
    "for i in tqdm.tqdm(range(benchmarkLoops)):\n",
    "    for epoch in range(epochs):\n",
    "        train_loss = train_epoch(model, train_loader, optimizer, scaler)\n",
    "        accuracy, report = test_model(model, test_loader)\n",
    "        # print time and loop number\n",
    "        print(f\"Loop {i+1} - Epoch {epoch+1} - Train Loss: {train_loss:.4f} - Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# End timer\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Elapsed time: {elapsed_time:.2f} seconds\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "Batch Size 5, 1 Epoch, 10 Iterations Mixed Precision\n",
    "\n",
    "* ARC A770 16GB (No AMP)\n",
    "  * Elapsed time: 229.07 seconds\n",
    "* RTX 4070 Super 12GB\n",
    "  * Elapsed time: 78.27 seconds\n",
    "* RTX 4070 Super 12GB On my PCIE 3.0 Lenovo P520 Workstation W-2135\n",
    "  * Elapsed time: 78.27 seconds\n",
    "* Titan Xp 12GB\n",
    "  * Elapsed time: 375.25 seconds\n",
    "* i9-14900K 5.4ghz all core locked 64GB 6800MHZ DDR5 20 threads\n",
    "  * Elapsed time: 2381.41 seconds\n",
    "* Ultra 155H ARC 16GB Total with 8GB Shared RAM (Laptop) (No AMP)\n",
    "  * Elapsed time: 1457.17 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
